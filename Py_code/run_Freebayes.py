#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Copyright (C) 2020 - Wolfgang Haas

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version (see <http://www.gnu.org/licenses/>).

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

The code development was partially supported byÂ the Public Health Emergency 
Preparedness grant number U9OTP216988, funded by Centers for Disease Control 
and Prevention as well as by Wadsworth Center, New York State Department of 
Health. Its contents are solely the responsibility of the authors and do not 
necessarily represent the official views of the Wadsworth Center or the New 
York State Department of Health.

************************************************************************


This module runs FreeBayes to search for SNPs and indels to produce a VCF file.
- Runs FreeBayes to call SNPs/indels and filters them with vcffilter
- Translates CIGAR scores from alphanumeric format to all-alphabetical for
  easy counting of all 'X', 'D', and 'I'
- Parses lines from a FreeBayes-style VCF-file
- Reads a VCF-file generated by FreeBayes vcffilter, 'freebayes.vcf', and 
  writes the summary data to report.txt
- Produces a histogram showing the distribution of SNPs in the genome

FreeBayes outputs a lot of SNPs by default in the expectation that they 
  will be filtered by the user.
In order to produce correct output, the reference supplied to FreeBayes must 
  be the same reference to which the reads in the BAM file were aligned. 
The REF_dir must also contain the FASTA index entry. 
FreeBayes uses as input a file called 'marked_duplicates.bam' created by 
  Samtools mpileup (see run_bwa.py) and Picard MarkDuplicates. 
FreeBayes calls SNPs, indels, MNPs (multi-nucleotide polymorphisms), and 
  complex events (composite insertion and substitution events).
BCFview and FreeBayes produce VCF-files of different formatting.

Note: the header in the reference needs to have the following form:
    >Species-And-Strain-Information_Contig_length_11111111_cov_1.000
    where:
        1) >
        2) Species-And-Strain-Information (separated by '-')  + '_'
        3) Conitg-info (separated by '-')  + '_'
        4) length (literal)  + '_'
        5) number (length of the sequence)  + '_'
        6) cov (literal)  + '_'
        7) a float or 1.000 if the coverage is unknown

@authors: 
    Wolfgang Haas, Pascal Lapierre, and Kimberlee A. Musser
    Wadsworth Center, New York State Department of Health
    120 New Scotland Ave., Albany, New York 12208
    wolfgang.haas@health.ny.gov
    
last update: 24 September 2020     
"""


import matplotlib
# sets the backend to anti-grain geometry for .png output
# prevents RuntimeError: Invalid DISPLAY variable in Linux
matplotlib.use('agg')
import matplotlib.pyplot as plt
import os
from numpy import ceil
import config
import toolshed



BASE_PATH   = config.get_DO_PATHS()['BASE_PATH']
TEMP_dir    = config.get_DO_PATHS()['TEMP_dir']
REF_dir     = config.get_DO_PATHS()['REF_dir'] 


Samtools_image, Samtools_WorkingDir   = config.get_DO_IMAGES()['Samtools']
Freebayes_image, Freebayes_WorkingDir = config.get_DO_IMAGES()['Freebayes']
VCFlib_image, VCFlib_WorkingDir       = config.get_DO_IMAGES()['VCFlib']




def run_samtools_faidx(work_dir, SS_dir, ref_fa_file):
    
    '''
    Generates a FAI index file, required for FreeBayes.
      Usage: samtools faidx <file.fa|file.fa.gz> [<reg> [...]]
    param: str work_dir = isolate-specific folder, e.g.: 'WH200812_001259/'
    param: str SS_dir = species-specific directory, e.g.: 'Lpn/'
    param: str ref_fa_file = name of a reference strain's FASTA file
    return: ReturnCode, StdOut, StdErr
    output: index files
    '''

    print('\nrunning: Samtools faidx')
    
    # command = 'docker run --rm=True -u $(id -u):$(id -g) '\
    #         + '-v "' + BASE_PATH + REF_dir + SS_dir\
    #         + ':' + Samtools_WorkingDir + '" '\
    #         + '-i ' + Samtools_image + ' samtools faidx '\
    #         + ref_fa_file
    
    run_dir = BASE_PATH + REF_dir + SS_dir
    base_cmd = (
        f'samtools faidx {ref_fa_file}'
    )
    command = toolshed.create_singularity_cmd(BASE_PATH, run_dir, Samtools_image, base_cmd)

    ReturnCode, StdOut, StdErr = toolshed.run_subprocess(work_dir, command, True)     

    with open(BASE_PATH + TEMP_dir + work_dir + 'log.txt', 'a') as log_file:
        print('\nsamtools faidx:\n', StdOut, file=log_file)
    
    return ReturnCode, StdOut, StdErr





def run_freebayes(work_dir, ref_fa_file, SS_dir, suffix):    
    '''
    Runs FreeBayes to call SNPs, INDELs, and complex mutations.
      -p INT    ploidy of the organism
      -f FILE   Use FILE as the reference sequence for analysis. An index file 
                (FILE.fai) will be created if none exists.
    param: str work_dir = isolate-specific folder, e.g.: 'WH200812_001259/'
    param: str ref_fa_file = name of a reference strain's FASTA file
    param: str SS_dir = species-specific directory, e.g.: 'Lpn/'
    param: str suffix = distinguishes files if more than one reference was 
           used for read mapping
    output: a VCF-file, 'freebayes_all.vcf'    
    '''

    print('\nrunning: Freebayes')
    
    # command = 'docker run'\
    #         + ' -v "' + BASE_PATH\
    #         + ':' + Freebayes_WorkingDir + '" '\
    #         + '-i ' + Freebayes_image + ' freebayes '\
    #         + '-f ' + REF_dir + SS_dir + ref_fa_file + ' '\
    #         + '-p 1 '\
    #         + TEMP_dir + work_dir + 'marked_duplicates' + suffix + '.bam '\
    #         + '> ' + BASE_PATH + TEMP_dir + work_dir + 'freebayes_all.vcf'
    
    run_dir = BASE_PATH
    base_cmd = (
        f'freebayes '
        f'-f {REF_dir + SS_dir + ref_fa_file} '
        f'-p 1 '
        f'{TEMP_dir + work_dir}marked_duplicates{suffix}.bam '
        f'> {BASE_PATH + TEMP_dir + work_dir}freebayes_all.vcf'
    )
    command = toolshed.create_singularity_cmd(BASE_PATH, run_dir, Freebayes_image, base_cmd)

    ReturnCode, StdOut, StdErr = toolshed.run_subprocess(work_dir, command, True)     

    with open(BASE_PATH + TEMP_dir + work_dir + 'log.txt', 'a') as log_file:
        print('\nFreebayes:\n', StdOut, file=log_file)
    
    return ReturnCode, StdOut, StdErr

    


def run_vcffilter(work_dir, DP_max):    
    '''
    Runs vcffilter to remove low quality SNp.
    param: str work_dir = isolate-specific folder, e.g.: 'WH200812_001259/'
    param: int DP_max = maximum total read depth at that SNP locus
    output: a VCF-file, 'freebayes.vcf'    
    '''

    print('\nrunning: vcffilter')
    
    # filtering thresholds to sort out low probability SNPs
    QUAL_threshold = 20     # min SNP quality (phred scale)
    DP_min         = 10     # min Total read depth at the locus
    QA_threshold   = 20     # min Alternate allele quality sum (phred scale)
    AO_DP_ratio    = 0.899  # min percentage of reads supporting the SNP, where 
                            #   AO is the Count of full observations of this 
                            #   alternate haplotype.
    # hard filter implemented as per Erik Garrison (see command):
    # SAF > 0 & SAR > 0   # remove alleles that are only seen on one strand

    # command = 'docker run'\
    #         + ' -v "' + BASE_PATH\
    #         + ':' + VCFlib_WorkingDir + '" '\
    #         + '-i ' + VCFlib_image + ' vcffilter '\
    #         + '-f  "QUAL > ' + str(QUAL_threshold) + ' '\
    #         + '& DP > ' + str(DP_min) + ' & DP < ' + str(DP_max) + ' '\
    #         + '& QA > ' + str(QA_threshold) + ' '\
    #         + '& SAF > 0 & SAR > 0 ' \
    #         + '& AO > ' + str(AO_DP_ratio) + ' * DP" '\
    #         + TEMP_dir + work_dir + 'freebayes_all.vcf '\
    #         + '> ' + BASE_PATH + TEMP_dir + work_dir + 'freebayes.vcf'
    
    run_dir = BASE_PATH
    base_cmd = (
        f'vcffilter '
        f'-f  "QUAL > {str(QUAL_threshold)} '
        f'& DP > {str(DP_min)} '
        f'& DP < {str(DP_max)} '
        f'& QA > {str(QA_threshold)} '
        f'& SAF > 0 '
        f'& SAR > 0 ' 
        f'& AO > {str(AO_DP_ratio)} * DP" '
        f'{TEMP_dir + work_dir}freebayes_all.vcf '
        f'> {BASE_PATH + TEMP_dir + work_dir}freebayes.vcf'
    )
    command = toolshed.create_singularity_cmd(BASE_PATH, run_dir, VCFlib_image, base_cmd)

    ReturnCode, StdOut, StdErr = toolshed.run_subprocess(work_dir, command, True)     

    with open(BASE_PATH + TEMP_dir + work_dir + 'log.txt', 'a') as log_file:
        print('\nFreebayes:\n', StdOut, file=log_file)
    
    return ReturnCode, StdOut, StdErr



def translate_CIGAR(CIGAR):  
    
    """ 
    Translates a CIGAR score from alphanumeric format to all-alphabetical for 
      easy counting of all 'X', 'D', and 'I'
    helper function to read_VCF_file()
    param: str CIGAR = a CIGAR score in ther form '#M#X#I#D', where # is the 
           count and Match, eXchanged (mismatch), Insertion, Deletion; e.g.: 
           '1X2M2X1I3M'
    return: a cigar string with only alphabetical characters, e.g. 'XMMXXIMMM'
    """

    number = ''
    letter = ''
    tl_cigar = ''          # translated CIGAR string: 'XXX' instead of '3X'
    for c in CIGAR:        # character by character
        if c.isnumeric():  # if number
            number += c    # reassemble the number
        elif c.isalpha():  # if letter
            letter = c
            subcigar = (int(number) * letter)  # replaces '3X' with 'XXX'
            tl_cigar += subcigar       # reassemble complete CIGAR string
            number = ''    # reset
            letter = ''    # rest
    return tl_cigar       

#assert translate_CIGAR('1X2M2X1I3M') == 'XMMXXIMMM'




def parse_FB_vcf_line(vcf_line): 
    
    """ 
    Parses a line from a FreeBayes-style VCF-file. 
    helper function to read_VCF_file()
    NOTE: CHROM is the header of each contig or genome and has been edited for
          each reference genome to match the SPAdes output for contigs, which
          includes the length of the contig, coverage is set to 1.0 if unknown
    param: str vcf_line = a line of data from a VCF-file
    return: (contig name, contig position, variant POSition, REFerence 
            sequence, ALTernative sequence, QUALity score, TYPE of mutation 
            (snp, mnp, ins, del, or complex), and the CIGAR string (Match, 
            eXchange, Deletion, Insertion))
    example line (split for readability):
        CHROM:  S-paucimobilis-NBRC-13935_NZ-BBJS00071.2_length_10828_cov_1.000	
        POS:    32577	
        ID:     .	
        REF:    A	
        ALT:    T	
        QUAL:   1729.33	
        FILTER: .	
        INFO:   AB=0;ABP=0;AC=1;AF=1;AN=1;AO=52;CIGAR=1X;DP=52;DPB=52;DPRA=0;
                EPP=4.51363;EPPR=0;GTI=0;LEN=1;MEANALT=1;MQM=60;MQMR=0;NS=1;
                NUMALT=1;ODDS=398.192;PAIRED=1;PAIREDR=0;PAO=0;PQA=0;PQR=0;
                PRO=0;QA=1954;QR=0;RO=0;RPL=26;RPP=3.0103;RPPR=0;RPR=26;RUN=1;
                SAF=23;SAP=4.51363;SAR=29;SRF=0;SRP=0;SRR=0;TYPE=snp	
        FORMAT: GT:DP:AD:RO:QR:AO:QA:GL	
        OTHER:  1:52:0,52:0:0:52:1954:-176.103,0
    """     
    
    # the entries in a line of a vcf-file
    CHROM, POS, ID, REF, ALT, QUAL, FILTER, INFO, FORMAT, OTHER \
    = vcf_line.split()
    # extract the contig length from the header
    contig_name = CHROM.split('_')[1]
    contig_len = CHROM.split('_')[3]
    lo_infos = INFO.split(';')
    for info in lo_infos:
        if info.startswith('CIGAR'):
            CIGAR = info.split('=')[1]
        elif info.startswith('TYPE'):
            TYPE = info.split('=')[1]
    return (contig_name, int(contig_len), int(POS), REF, ALT, float(QUAL),  
            TYPE, CIGAR)

#a_vcf_line = 'Sphingomonas-paucimobilis-NBRC-13935_NZ-BBJS01000071.2_length'\
#+'_10828_cov_1.000	  5100	. TGTG CCTT	3022.5	. AB=0;ABP=0;AC=1;AF=1'\
#+';AN=1;AO=94;CIGAR=2X1M1X;DP=94;DPB=94.25;DPRA=0;EPP=10.4949;EPPR=0;GTI=0;'\
#+'LEN=4;MEANALT=1;MQM=57.9894;MQMR=0;NS=1;NUMALT=1;ODDS=695.957;PAIRED=0.98'\
#+'9362;PAIREDR=0;PAO=1;PQA=33;PQR=0;PRO=0;QA=3431;QR=0;RO=0;RPL=53;RPP=6.33'\
#+'681;RPPR=0;RPR=41;RUN=1;SAF=51;SAP=4.48875;SAR=43;SRF=0;SRP=0;SRR=0;TYPE='\
#+'complex	GT:DP:AD:RO:QR:AO:QA:GL	1:94:0,94:0:0:94:3431:-306.729,0'
#assert parse_FB_vcf_line(a_vcf_line) == ('NZ-BBJS01000071.2', 10828, 5100, 
#                                         'TGTG', 'CCTT', 3022.5, 'complex', 
#                                         '2X1M1X')



def read_VCF_file(work_dir):
    
    """ 
    Reads a VCF-file generated by FreeBayes, 'freebayes.vcf' and returns a 
      list of the position of mutations.
    param: str work_dir = isolate-specific folder, e.g.: 'WH200812_001259/'
    return: lo_variant_posns = list of positions of SNPs and indels, used to
            plot their distributions
    return: int V1 = mutation events (SNPs + indel events)
    return: int V2 = number of indel events, regardless of length
    return: int V3 = number of bases in indels
    return: int V4 = SNP count
    """      

    # lists of numbers, where each number is a position in the reference genome
    lo_variant_posns = []  # list containing all SNPs and bases in indels
                           #  used for plotting distribution of SNPs and indels
    lo_mutation_posns = [] # list containing all SNPs and indel events
    cum_length  = 0        # cumulative position (contig lengths summed up)
    prev_contig = 'none'   # name of previous contig
    prev_length = 0        # length of previous contig    
    SNP_count   = 0        # counts all individual SNPs ('X' in CIGAR)
    event_count = 0        # counts all indel events (where D = DDD = I = III)
    
    # extract data from the vcf-file    
    with open (BASE_PATH + TEMP_dir + work_dir + 'freebayes.vcf', 'r')\
    as in_file:
        for line in in_file:
            line = line.rstrip('\n')
            if line.startswith('#'): # ignore header or comment rows
                continue
            else: 
                contig_name, contig_len, POS, REF, ALT, QUAL, TYPE, CIGAR \
                = parse_FB_vcf_line(line)
                
                # if new contig, add the length from the previous contig 
                # to the cumulative length, then update name and length
                if contig_name != prev_contig:
                    cum_length += prev_length
                    prev_length = contig_len
                    prev_contig = contig_name
                     
                # get the position of the variant within the translated
                # CIGAR string, calculate the position of the variant within
                #  the genome, and add it to the list
                tl_cigar = translate_CIGAR(CIGAR)
                
                last_string = ''

                for index,string in enumerate(tl_cigar):
                    
                    # variant count
                    # each SNP, ins, or del counted as one individual mutation
                    if string in ['X','I','D']:
                        lo_variant_posns.append(cum_length + POS + index)
                    
                    # SNP count, individually
                    if string == 'X': 
                        lo_mutation_posns.append(cum_length + POS + index)
                        SNP_count += 1                        
                    # indel event count
                    # only the first inserted or deleted base of an indel is 
                    # counted if more of the same follows; e.g.: I and IIIIII
                    # are counted both only as one mutation event; two events
                    # in the same CIGAR, e.g. DDDDIIII, are counted as two
                    # for consistency with compare_SNP_files.py
                    elif string == 'I' and last_string != 'I':
                        lo_mutation_posns.append(cum_length + POS + index)
                        event_count += 1
                        last_string = 'I'
                    elif string == 'D' and last_string != 'D':
                        lo_mutation_posns.append(cum_length + POS + index)
                        event_count += 1
                        last_string = 'D'

    # these should be the same values as obtained by compare_SNP_files.py
    V1 = len(lo_mutation_posns)             # SNPs + indel events
    V2 = event_count                        # indel events
    V3 = len(lo_variant_posns) - SNP_count  # bases in indels
    V4 = SNP_count                          # SNPs
                  
    return lo_variant_posns, V1, V2, V3, V4




def write_to_file(work_dir, ref_fa_file, isolate, to_mutations, ref_seq_len, 
                  SNP_THRESHOLD):
    
    """ 
    Writes the summary data from the FreeBayes VCF file to report.txt.
    param: str work_dir = isolate-specific folder, e.g.: 'WH200812_001259/'
    param: str ref_fa_file = name of a reference strain's FASTA file
    param: str isolate = isolate name, e.g.: 'IDR001234'
    param: tup to_mutations = (V1, V2, V3, V4)
    param: int ref_seq_len = length of the reference genome
    param: int SNP_THRESHOLD = number of mutation events (formerly SNPs only)
           above which an isolote will be added to the list of candidate 
           reference genomes
    output: summary statistics written to the report file
    """      

    # turn the int into str
    V1, V2, V3, V4 = [str(V) for V in to_mutations]
    data_str = V1 + ' (' + V2 + ', ' +  V3 + ', ' + V4 + ')' 

    # write results to the report
    with open(BASE_PATH + TEMP_dir + work_dir + 'report.txt', 'a') as report:
        print('\n\nSNPs and INDEL events between ' + isolate\
              + ' and reference ' + ref_fa_file[:-3] + ' (FreeBayes):', 
              file=report)

        print('\nFound', data_str, 'SNPs and INDEL events compared to a ' \
              + 'reference genome of', ref_seq_len, 'bp.', file=report)
        print('(Note that the indel event count might be slightly lower in'\
              ' the SNP-matrix.)\n', file=report)

        # if too many SNPs/INDELs, make the query it's own reference
        if to_mutations[0] >= SNP_THRESHOLD:
            print('\nNOTE:\nNumber of SNPs and INDEL events above threshold. '\
                  + 'Adding the isolate to the list of reference genomes.', 
                  file=report)
        
        print('Figure: SNP/INDEL distribution', file=report)
           



def plot_mutation_dist(work_dir, isolate, lo_variant_posns, ref_seq_len):   
            
    """ 
    Produces a histogram showing the distribution of SNPs in the genome.
      FreeBayes combines SNPs and indels into MNPs (multi-nucleotide 
      polymorphisms) or complex events (composite insertion and substitution 
      events), which have been unravelled into single mutations.
    param: str work_dir = isolate-specific folder, e.g.: 'WH200812_001259/'
    param: str isolate = isolate name, e.g.: 'IDR001234'
    param: int ref_seq_len = length of the reference genome
    param: list lo_variant_posns = list of positions of SNPs and indels
    output: a histogram, 'mutation_dist.png', that shows the number of SNPs 
            and number of bases in indels in intervals (bins) of 5000 bases
    """

    fig, ax = plt.subplots()
    max_x_val = int(ceil(ref_seq_len/500000)) + 1  # highest value on x-axis
    # print a histogram to file, were each bin covers about 5000 bp of the 
    #   genome over the length of the genome
    plt.hist(lo_variant_posns, bins=int(ref_seq_len/5000), \
             range=(0, ref_seq_len)) 
    plt.title('SNP/indel distribution for ' + isolate + ' in 5 kb intervals')
    plt.xlabel('Position [million bases]')
    plt.ylabel('Number of mutations per 5kb')    
    # change the tick labels: for a genome of 3.5 Mb, need a tick label every
    #   0.5 Mb or 500000 bp => make 8 tick labels (0, 0.5, 1, ...)
    # choose which x locations to have ticks: every 500 kb
    ax.set_xticks([500000 * x for x in range(0, max_x_val)]) 
    # set the labels to display at those ticks: 500 kb intervals
    ax.set_xticklabels([0.5 * x for x in range(0, max_x_val)])
    plt.savefig(BASE_PATH + TEMP_dir + work_dir + 'mutation_dist.png')
    plt.close()




def seq_len(SS_dir, ref_fa_file):
    
    """ 
    Returns the length of the reference genome in bp.
    param: str SS_dir = species-specific directory, e.g.: 'Lpn/'
    param: str ref_fa_file = name of a reference strain's FASTA file
    return: int length of the sequence
    """

    seq = ''
    with open(BASE_PATH + REF_dir + SS_dir + ref_fa_file, 'r') as infile:
        for line in infile:
            line = line.rstrip('\n')
            if not line.startswith('>'):
                seq = seq + line
    return len(seq)




def main(SS_dir, work_dir, ref_fa_file, isolate, DP_max, suffix, 
         SNP_THRESHOLD):
    
    """ 
    Main function
    param: str SS_dir = species-specific directory, e.g.: 'Lpn/'
    param: str work_dir = isolate-specific folder, e.g.: 'WH200812_001259/'
    param: str ref_fa_file = name of a reference strain's FASTA file
    param: str isolate = isolate name, e.g.: 'IDR001234'
    param: int DP_max = maximum total read depth at that SNP locus
    param: str suffix = distinguishes files if more than one reference was 
           used for read mapping
    param: int SNP_THRESHOLD = number of mutation events (formerly SNPs only)
           above which an isolote will be added to the list of candidate 
           reference genomes
    output: text added to report.txt
    return: tup to_mutations = (V1, V2, V3, V4)
    return: int ref_seq_len = the length of the refernce genome in bp
    """

    # runs 'samtools faidx' to create an index file of the ref_fa_file file if 
    # it does not already exist
    if not os.path.exists(BASE_PATH + REF_dir + ref_fa_file + '.fai'):
        run_samtools_faidx(work_dir, SS_dir, ref_fa_file)
        
    # calls SNPs and INDELs and complex mutations and filters them
    run_freebayes(work_dir, ref_fa_file, SS_dir, suffix)
    print('\n## run_freebayes() complete')  
          
    run_vcffilter(work_dir, DP_max)
    print('\n## run_vcffilter() complete')  
    
    # reads the freebayes VCF file and writes the data to report.txt
    lo_variant_posns, V1, V2, V3, V4 = read_VCF_file(work_dir)
    print('\n## read_VCF_file() complete')    
    
    # return a tuple of values for SNPs and indel counts
    to_mutations = (V1, V2, V3, V4)
      
    # returns the length of the refernce genome in bp
    ref_seq_len = seq_len(SS_dir, ref_fa_file)
    print('\n## seq_len() complete') 
    
    # makes a plot of the SNP distribution
    plot_mutation_dist(work_dir, isolate, lo_variant_posns, ref_seq_len)
    print('\n## get_mutation_dist() complete')    
            
    # adds text to the report file
    write_to_file(work_dir, ref_fa_file, isolate, to_mutations, ref_seq_len, 
                  SNP_THRESHOLD)
            
    return to_mutations, ref_seq_len




